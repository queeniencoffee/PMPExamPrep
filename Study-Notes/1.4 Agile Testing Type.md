# Agile Testing & Learning Approaches: TDD, BDD, ATDD, Spikes & Acceptance Testing

This document summarizes and compares **Test-Driven Development (TDD)**, **Behavior-Driven Development (BDD)**, **Acceptance Test-Driven Development (ATDD)**, and **Spikes**, and then outlines other **acceptance testing practices** commonly used in Agile.

---

## 1. Quick Definitions

### Test-Driven Development (TDD)

**Focus:**  
Code design and correctness at the **unit level**.

**Core idea:**  
> Write a failing **unit test first**, then write just enough code to make it pass, then refactor.

**Classic TDD cycle (Red–Green–Refactor):**

1. **Red** – Write a small failing test (e.g., for a single function or method).  
2. **Green** – Implement the minimal code to make the test pass.  
3. **Refactor** – Clean up the code while keeping all tests passing.

**Typical tests:**

- Unit tests (methods, classes, small components).  
- Written in code by developers using frameworks such as JUnit, NUnit, pytest, etc.

**Main goal:**  
- Better code design and structure.  
- Fewer defects.  
- Safe refactoring and easier maintenance.

---

### Behavior-Driven Development (BDD)

**Focus:**  
System **behavior** from the **user or business perspective**.

**Core idea:**  
> Describe behavior in **plain language** (often “Given–When–Then” scenarios), then automate those scenarios as tests.

**Typical BDD flow:**

1. Collaborate (PO, BA, QA, devs) to define **examples of desired behavior**:
   - **Given** some context  
   - **When** an action happens  
   - **Then** an observable outcome should occur  

2. Capture these scenarios in a structured format (e.g., Gherkin).  
3. Automate them using tools (e.g., Cucumber, SpecFlow, Behave, JBehave).

**Typical tests:**

- Acceptance / scenario / behavior tests.  
- Often span multiple components, closer to end-to-end or high-level functional tests.

**Main goal:**

- Shared understanding of expected behavior.  
- Ensure the system behaves as the business expects.  
- Reduce misinterpretation of requirements.

---

### Acceptance Test-Driven Development (ATDD)

**Focus:**  
**Acceptance criteria** and **acceptance tests** defined **before** development.

**Core idea:**  
> The team collaborates to define **acceptance tests first**, then writes code to make those tests pass.

**Typical ATDD flow:**

1. For each story/feature, the team (PO/BA, QA, developers) defines **acceptance criteria** and **acceptance tests** that describe “what must be true for this to be accepted.”  
2. These acceptance tests become a **contract** for what “done” means.  
3. Developers implement the feature until all acceptance tests pass.

**Tests:**

- Story/feature-level acceptance tests.  
- May be written in Gherkin or other human-readable forms, and automated.

**Relationship to BDD:**

- Many teams treat **BDD as a style of ATDD**:
  - **ATDD** is about *acceptance tests first*.  
  - **BDD** is about *describing behavior with examples and domain language*, usually implemented as acceptance tests.

**Main goal:**

- Build the **right thing** by aligning implementation with explicit acceptance criteria from the start.

---

### Spike

**Focus:**  
**Learning and research**, not direct feature delivery.

**Definition:**  
A **time-boxed investigation** or experiment to reduce uncertainty (technical, functional, or design-related).

**Examples:**

- Evaluate two frameworks and recommend one.  
- Prototype a minimal integration to understand an external API.  
- Explore performance characteristics of a new database choice.  

**Output:**

- Knowledge, options, a prototype, and/or refined estimates.  
- Often captured as documentation, proof-of-concept code, or recommendations.

**Important:**  
- A **spike is a type of backlog item**, not a testing method.  
- It may lead to better TDD/BDD/ATDD scenarios and more realistic estimates.

---

## 2. Side-by-Side Comparison: TDD vs BDD vs ATDD vs Spike

| Aspect                     | **TDD (Test-Driven Development)**               | **BDD (Behavior-Driven Development)**                              | **ATDD (Acceptance Test-Driven Development)**                       | **Spike**                                                                 |
|----------------------------|-------------------------------------------------|--------------------------------------------------------------------|---------------------------------------------------------------------|---------------------------------------------------------------------------|
| Primary focus              | Code design & **unit-level correctness**        | System **behavior** from **user/business** perspective             | Meeting defined **acceptance criteria** for stories/features        | **Reducing uncertainty** via research/experiment                         |
| Main question              | “Does this function/class work correctly?”      | “Does the system behave as the user expects?”                      | “Does this story/feature satisfy the acceptance tests?”             | “What do we need to learn to decide/estimate/implement safely?”          |
| Typical test level         | Unit tests                                      | Acceptance / behavior / scenario tests                             | Story/feature-level acceptance tests                                | Often no formal tests; may produce PoC code or future test ideas         |
| Who collaborates           | Mostly developers                               | PO/BA + QA + developers                                            | PO/BA + QA + developers                                             | Usually developers + architect + sometimes PO                             |
| Expression style           | Code-centric tests (xUnit frameworks)           | Structured natural language (e.g., **Given–When–Then**)            | Acceptance criteria & tests (may use Gherkin or similar)            | Notes, prototype, findings, and recommendations                          |
| When used                  | Continuously during coding                      | During discovery + development and refinement of behavior          | Before and during implementation of stories/features                | Before or early in implementation / estimation                           |
| Main benefit               | Clean design, fewer bugs, safe refactoring      | Shared understanding, behavior aligned with business expectations  | Clear definition of “done”, fewer misunderstandings                 | Lower risk, better estimates, more informed design and technology choices |
| Exam / Agile angle         | Test-first, unit-level, dev-driven              | Example-based, behavior-focused, cross-role collaboration          | Acceptance-test-first, ensures story/feature meets acceptance tests | Time-boxed learning story to explore unknowns                             |

---

## 3. Other Acceptance Testing Practices in Agile

While TDD, BDD, and ATDD are common “named” practices, Agile teams typically use several **forms of acceptance testing**. Key ones to understand:

### 3.1 User Acceptance Testing (UAT)

- Performed by **end users or business representatives**.  
- Validates that the product:
  - Meets business needs.  
  - Works in a realistic or staging environment.  
- Often conducted:
  - Before major releases.  
  - At the end of a larger increment or iteration.  

**Goal:** Confirm the system is acceptable for production use from the business/user standpoint.

---

### 3.2 Story-Level Acceptance Criteria & Acceptance Tests

- Each user story includes **clear acceptance criteria**, typically written as a bullet list.  
- These criteria describe:
  - What conditions must be true for the story to be considered “done.”  
- Teams often:
  - Turn these criteria into **manual acceptance test cases** or  
  - Automate them, aligning with **ATDD/BDD** practices.

**Connection to Definition of Done (DoD):**

- A story cannot be “done” unless:
  - All acceptance criteria are met  
  - And related acceptance tests pass.

---

### 3.3 System / End-to-End (E2E) Acceptance Tests

- Validate **end-to-end workflows** that cross multiple components or services.  
- Typical examples:
  - Full e-commerce purchase flow (browse → add to cart → pay → confirm).  
  - Full insurance claim lifecycle (submit → review → approve/deny → notify).  

**Goal:** Ensure that integrated systems deliver the expected **business value** and user experience.

---

### 3.4 Non-Functional Acceptance Tests

- Focus on **quality attributes** such as:
  - Performance  
  - Security  
  - Reliability  
  - Usability  
  - Scalability  
- Examples:
  - “System must support 1,000 concurrent users with checkout response time < 2 seconds.”  
  - “Passwords must meet complexity rules and be securely stored.”

**Goal:** Ensure the system meets **non-functional requirements** that are critical to real-world use.

---

### 3.5 Specification by Example (SBE)

- A **collaborative specification technique**, very close to BDD/ATDD.  
- Requirements are captured as **concrete examples**, which then become:
  - Living documentation  
  - Automated acceptance tests  

**Key ideas:**

- Examples clarify ambiguous requirements.  
- The same examples are used for:
  - Understanding  
  - Development  
  - Testing  
  - Documentation  

---

### 3.6 Exploratory Testing (often used alongside acceptance testing)

- Tester explores the system using **charters**, time-boxed sessions, and real-time learning.  
- Not strictly scripted; relies on tester skill, creativity, and domain knowledge.  
- Complements scripted acceptance tests to discover:
  - Edge cases  
  - Usability issues  
  - Unexpected behaviors  

**Goal:** Find issues that formal acceptance tests might miss.

---

## 4. Exam-Memory Summary (PMP / Agile)

Use these concise lines as a quick memory aid:

- **TDD:**  
  *“Write unit tests first to drive code design and correctness (Red–Green–Refactor).”*

- **BDD:**  
  *“Describe expected behavior in business-readable scenarios (Given–When–Then) and automate them.”*

- **ATDD:**  
  *“Define acceptance tests before coding so implementation is guided by acceptance criteria.”*

- **Spike:**  
  *“Time-boxed research or prototype to reduce uncertainty, not a test method itself.”*

- **Acceptance testing in Agile:**  
  - Story-level acceptance criteria & tests  
  - User Acceptance Testing (UAT)  
  - End-to-end / system acceptance tests  
  - Non-functional acceptance tests  
  - Specification by Example (often with BDD/ATDD)  
  - Exploratory testing as a complementary approach

---
